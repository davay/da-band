{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#description","title":"Description","text":"<p>This is a project using uMyo EMG sensors to make a wristband, which sends data to an iPhone via Bluetooth, which is then used to perform gesture classification. </p> <p>Each gesture can then be paired with an action. An action can be any API call that can be performed by the phone, such as HomeKit and Shortcuts APIs.</p> <pre><code>graph LR\n    uMyo[/uMyo EMG Sensors/]\n    Classifier{Gesture Classification}\n    GestureA(Finger Snap)\n    GestureB(Hand Clap)\n    GestureC(Gesture C)\n    ActionA(HomeKit: Lights Off)\n    ActionB(Shortcuts: Start Timer)\n    ActionC(Action C)\n\n    subgraph iPhone[iPhone]\n        Classifier --&gt; GestureA\n        Classifier --&gt; GestureB\n        Classifier --&gt; GestureC\n\n        GestureA --&gt;|API Call| ActionA\n        GestureB --&gt;|API Call| ActionB\n        GestureC --&gt;|API Call| ActionC\n    end\n\n    uMyo --&gt;|Bluetooth LE| Classifier</code></pre>"},{"location":"#motivation","title":"Motivation","text":"<ul> <li>uMyo right now provides 3 connection modes:<ul> <li>skip the middleman</li> <li>phones are powerful</li> </ul> </li> <li>The decoupling of Gestures and Actions provides lots of possibilities</li> <li>Learning experience, as I'm looking to break into this field of HCI/BCI/AR </li> <li>Meta Orion, JRE</li> <li>Problems with current AR control methods: hand has to be in front of camera -&gt; tiring, awkward</li> </ul>"},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>da-band/\n\u251c\u2500\u2500 api/       # A FastAPI server, for certain ML tasks like initial model creation\n\u251c\u2500\u2500 band/      # A PlatformIO-managed arduino project for wristband firmware\n\u251c\u2500\u2500 docs/      # An Mkdocs-material docs for this project\n\u251c\u2500\u2500 ios/       # A Tuist-managed Xcode project for the iOS app\n\u251c\u2500\u2500 models/    # Trained PyTorch/CoreML models\n\u2514\u2500\u2500 notebooks/ # Jupyter notebooks used for exploration\n</code></pre>"},{"location":"#milestones","title":"Milestones","text":"Milestone Status Description M1 A binary classification model for 1 gesture is ready to be used. Manually tap a button in the iOS app to start listening for 3 seconds and perform exactly 1 instance of the trained gesture. M2 A multi-class classification model for 2 or more gestures are ready to be used. iOS app continuously receives data and calculates probabilities of gesture activation using a rolling window of past 3 seconds of data, every second. If the highest probability exceeds some threshold, trigger that gesture. M3 Whenever a gesture triggers, send notification to user asking whether it was an accurate detection. If yes, store as a new sample for future fine-tuning. M4 Band only sends data after some trigger and is inactive otherwise. Trigger can be some threshold for a feature(s), or perhaps fit the band with a gyroscope so that it needs to be raised before it turns on (ala an Apple Watch.)"},{"location":"api/","title":"API","text":""},{"location":"api/#status","title":"Status","text":"<p>TODO</p>"},{"location":"api/#description","title":"Description","text":"<p>This API server's primary purpose is to receive data from the iOS app and train initial CoreML models -- since iOS apps can't train initial models, they can only finetune.</p>"},{"location":"api/#api-design","title":"API Design","text":""},{"location":"api/#authentication","title":"Authentication","text":"<p>To make this simpler, there will be no user accounts. Instead, operations will be tied to a wristband_id (since each dataset and model is specific to a wristband anyway).</p> <p>The flow will look something like this: </p> <ol> <li>Generate a random UUID when creating/connecting a new wristband in the app</li> <li>Use this UUID in all request headers</li> <li>Add basic rate limiting per UUID (e.g., 100 requests per hour)</li> </ol> <p>This should be enough to stop the simplest of attacks -- the goal here isn't to make a commercial product, this is a personal project. </p> <p>In the future, we have many options to improve security:</p> <ul> <li>Implement user accounts; OR </li> <li>Generate the wristband_id by hashing a combination of each uMyo's device IDs (1 wristband can have many uMyos); OR </li> <li>IDs are generated per iOS device, and we can use hardware identifiers + DeviceCheck API for attestation</li> </ul>"},{"location":"api/#resources","title":"Resources","text":"<ul> <li>Wristbands: Paired wristbands.</li> <li>Gestures: User-named gestures. Each gesture is specific to a wristband.</li> <li>Datasets: EMG data uploaded from iOS devices. Each dataset is specific to a gesture.</li> <li>Models: Trained CoreML gesture classification models. Each model is specific to a wristband. Must be able to distinguish between gestures.</li> </ul>"},{"location":"api/#endpoints","title":"Endpoints","text":"<p>All requests must include <code>X-Wristband-ID: &lt;UUID&gt;</code> in the headers. Responses will be specific to the wristband.</p>"},{"location":"api/#gestures","title":"Gestures","text":""},{"location":"api/#get-gestures","title":"<code>GET /gestures</code>","text":"<ul> <li>List all gestures associated with a wristband.</li> <li>Response: <code>[{id, name, created_at}]</code></li> </ul>"},{"location":"api/#post-gestures","title":"<code>POST /gestures</code>","text":"<ul> <li>Create a new gesture</li> <li>Body: <code>{name}</code></li> <li>Response: <code>{id, name, created_at}</code></li> </ul>"},{"location":"api/#delete-gesturesgesture_id","title":"<code>DELETE /gestures/{gesture_id}</code>","text":"<ul> <li>Delete a gesture and all of its associated datasets and models (DANGEROUS!)</li> <li>Response: <code>204 No Content</code></li> </ul>"},{"location":"api/#datasets","title":"Datasets","text":""},{"location":"api/#post-datasetsgesture_id","title":"<code>POST /datasets/{gesture_id}</code>","text":"<ul> <li>Upload EMG data samples for a specific gesture</li> <li>Body: CSV file</li> <li>Response: <code>{id, gesture_id, created_at}</code></li> </ul>"},{"location":"api/#models","title":"Models","text":""},{"location":"api/#post-modelstrain","title":"<code>POST /models/train</code>","text":"<ul> <li>Triggers training a new model</li> <li>Body: <code>{gestures: [gesture_ids]}</code> (which gestures to include, maybe make it optional to use all gestures?)</li> <li>Response: <code>{id, version, status: \"training\"}</code></li> </ul>"},{"location":"api/#get-modelslateststatus","title":"<code>GET /models/latest/status</code>","text":"<ul> <li>Get status of latest model (e.g., training progress, ETA)</li> <li>Response: <code>{id, version, status, progress, eta}</code></li> </ul>"},{"location":"api/#get-modelsmodel_idstatus","title":"<code>GET /models/{model_id}/status</code>","text":"<ul> <li>Get status of specific model (e.g., training progress, ETA)</li> <li>Response: <code>{id, version, status, progress, eta}</code></li> </ul>"},{"location":"api/#get-modelslatest","title":"<code>GET /models/latest</code>","text":"<ul> <li>Download latest completed CoreML model</li> <li>Response: CoreML model file</li> </ul>"},{"location":"api/#get-modelsmodel_id","title":"<code>GET /models/{model_id}</code>","text":"<ul> <li>Download specific completed CoreML model</li> <li>Response: CoreML model file</li> </ul>"},{"location":"api/#db-design","title":"DB Design","text":"<ul> <li> <p>Wristband:</p> <ul> <li>id | PK</li> <li>created_at</li> </ul> </li> <li> <p>Gesture:</p> <ul> <li>id | PK</li> <li>wristband_id | FK</li> <li>name</li> <li>created_at</li> </ul> </li> <li> <p>Dataset: </p> <ul> <li>id | PK</li> <li>gesture_id | FK</li> <li>file_path (datasets will be stored as CSV on the server)</li> <li>created_at</li> </ul> </li> <li> <p>Model: </p> <ul> <li>id | PK</li> <li>wristband_id | FK</li> <li>version</li> <li>file_path (trained CoreML models)</li> <li>created_at</li> </ul> </li> <li> <p>ModelGesture: (junction table, to track which gestures can be recognized by a model, each model can have many versions)</p> <ul> <li>model_id | PK, FK</li> <li>gesture_id | PK, FK</li> </ul> </li> </ul>"},{"location":"band/","title":"Band","text":""},{"location":"band/#status","title":"Status","text":"<ol> <li>uMyo sensor supports 3 modes right now: RF24, RF52, and BLE Advertising mode. If we want to connect to iOS, BLE Advertising mode limits bandwidth too much. Need to reverse engineer and flash a firmware with BLE GATT capabilities.</li> <li>How to flash-over-the-air quickly</li> <li>If we're not going to be using the other modes, remap one of the button presses to pairing or something</li> </ol>"},{"location":"band/#development","title":"Development","text":""},{"location":"band/#dependencies","title":"Dependencies","text":"<p>The project was setup using platformio, so: </p> <pre><code>brew install platformio\n</code></pre>"},{"location":"band/#quick-start","title":"Quick Start","text":"<p>IDE: </p> <pre><code>TODO\n</code></pre> <p>Vim: </p> <pre><code>TODO\n</code></pre>"},{"location":"band/#flash-configs","title":"Flash configs","text":""},{"location":"band/#hardware","title":"Hardware","text":""},{"location":"band/#esp32-c3-mini-module","title":"ESP32-C3-MINI Module","text":""},{"location":"band/#naming-schemes","title":"Naming Schemes","text":"<p>So the model naming scheme is like: ESP32-C3-MINI-{1,1U}-{N4,H4}</p> <ul> <li>The 1/1U refers to the antenna option:<ul> <li>1: Onboard PCB antenna</li> <li>1U: External antenna via a connector</li> </ul> </li> <li>The N4/H4 refers to the chip used:<ul> <li>N4: Uses the ESP32-C3FN4 chip</li> <li>H4: Uses the ESP32-C3FH4 chip</li> </ul> </li> <li>Both of them are exactly the same 32-bit RISC-V single-core processor, except that the H4 supports higher operating temperature than the N4.</li> </ul>"},{"location":"band/#pin-definitions","title":"Pin Definitions","text":"Name No. Type Function GND 1, 2, 11, 14, 36-53 P Ground 3V3 3 P Power supply NC 4, 7, 9, 10, 15, 17, 24, 25, 28, 29, 32-35 \u2014 NC IO2 5 I/O/T GPIO2, ADC1_CH2, FSPIQ IO3 6 I/O/T GPIO3, ADC1_CH3 EN 8 I High: on, enables the chip.Low: off, the chip powers off.Note: Do not leave the EN pin floating. IO0 12 I/O/T GPIO0, ADC1_CH0, XTAL_32K_P IO1 13 I/O/T GPIO1, ADC1_CH1, XTAL_32K_N IO10 16 I/O/T GPIO10, FSPICS0 IO4 18 I/O/T GPIO4, ADC1_CH4, FSPIHD, MTMS IO5 19 I/O/T GPIO5, ADC2_CH0, FSPIWP, MTDI IO6 20 I/O/T GPIO6, FSPICLK, MTCK IO7 21 I/O/T GPIO7, FSPID, MTDO IO8 22 I/O/T GPIO8 IO9 23 I/O/T GPIO9 IO18 26 I/O/T GPIO18, USB_D- IO19 27 I/O/T GPIO19, USB_D+ RXD0 30 I/O/T GPIO20, U0RXD TXD0 31 I/O/T GPIO21, U0TXD"},{"location":"band/#abrobot-esp32-c3-mini-dev-module","title":"ABRobot ESP32-C3-MINI Dev Module","text":""},{"location":"band/#resources","title":"Resources","text":""},{"location":"docs/","title":"Docs","text":""},{"location":"docs/#status","title":"Status","text":"<p>TODO</p>"},{"location":"docs/#development","title":"Development","text":"<p>This documentation was built using mkdocs-material.</p>"},{"location":"docs/#dependencies","title":"Dependencies","text":"<pre><code>conda install mkdocs-material mkdocs-git-revision-date-localized-plugin mkdocs-glightbox\n</code></pre>"},{"location":"docs/#quick-start","title":"Quick Start","text":"<p>This project was created using <code>mkdocs new .</code>, all you need to do now is: </p> <pre><code>mkdocs serve\n</code></pre> <p>A GitHub actions pipeline has been setup, docs will be automatically updated on push to main. </p>"},{"location":"docs/#resources","title":"Resources","text":""},{"location":"glossary/","title":"Glossary","text":""},{"location":"glossary/#electronics","title":"Electronics","text":"Term Description Serial Peripheral Interace (SPI) A protocol for synchronous wired communication between devices through 4 types of logic signals (CS, SCLK, MOSI, MISO) implemented using 4 wires.Follows a master-slave architecture where the main device controls communication with other devices through using clock and chip select signals.Data flows in a circle; MOSI then MISO and so on. Data packets usually contain just raw data; no overhead necessary.Usually implemented as a hardware on the MCU, but can be done in software too. There are also often pins on the module to interface with the SPI. Logic Signals Electrical signals that represent binary values (0 or 1) through voltage level \u2014 e.g., in a 5V system, voltages close to 5V would represent \u20181\u2019 and 0V would represent \u20180\u2019. Clock Signal A continuous, regular oscillating signal commonly used in synchronous circuits to prevent race conditions.Applied to all storage devices, flip-flops, and latches; data transfers and operations occur on specific clock edges (rising/falling) so that all components change state simultaneously. Circuit Any path that electricity can flow through. Digital Circuit A circuit that works with 1s and 0s (binary). Integrated Circuit (IC) / Chip A general term for a single silicon die containing multiple circuits.  May just be the core processor itself or may be more of a system-on-a-chip that integrates other components like flash memory and wifi/bluetooth radio. Usually still needs other components to function though.E.g., ESP32-C3-FN4 Microcontroller Unit (MCU) A specific type of IC. Must contain CPU, memory, and I/O all in one chip. An MCU is an IC, but not all ICs are MCUs.E.g., ESP32-C3-FN4 Module A PCB consisting of a chip + other components like power management and I/O (or flash memory / RF if the chip doesn\u2019t have it yet.) E.g., ESP32-C3-MINI Printed Circuit Board (PCB) A board made of insulating material (e.g., fiberglass) to serve as a mounting surface for components. Universal Asynchronous Receiver-Transmitter (UART) A protocol for asynchronous (no clock signal) wired communication between devices through 2 types of logic signals (TX, RX) implemented using 2 wires. Follows a peer-to-peer architecture."},{"location":"glossary/#spi-logic-signals","title":"SPI Logic Signals","text":"Abbreviation Name Description CS Chip Select A signal from main device to choose which sub-device to talk to. SCLK Serial Clock Clock signal from main. MOSI Main Out, Sub In Serial data; main \u2192 sub. MISO Main In, Sub Out Serial data; sub \u2192 main."},{"location":"ios/","title":"iOS App","text":""},{"location":"ios/#status","title":"Status","text":"Related Milestone Task Status Description M1 Setup BLE Communication Implement basic BLE connection and data reception M1 Create Recording UI Button UI for 3-second recording M2 Implement Rolling Window Process continuous data stream with 3s window M3 Add Notification System User feedback notifications for gesture detection M4 Power Management UI Interface to show band's power state"},{"location":"ios/#development","title":"Development","text":""},{"location":"ios/#dependencies","title":"Dependencies","text":"<p>This project uses Tuist</p> <pre><code>brew install --cask tuist\n</code></pre> <p>See Bumble's article on SPM vs Tuist vs Bazel (part 3/3 here)</p>"},{"location":"ios/#quick-start","title":"Quick Start","text":"<p>The project was created using <code>tuist init</code>. By default it creates a project that represents an iOS application. </p> <p>The project directory will contain a Project.swift, which describes the project, a Tuist.swift, which contains project-scoped Tuist configuration, and \\&lt;app-name&gt;/, which contains the source code of the application. </p> <p>Note that unlike Xcode projects, which you can open and edit directly, Tuist projects are generated from a manifest file. This means that you should not edit the generated Xcode project directly.</p> <p>To work on it in Xcode:</p> <pre><code>tuist generate\n</code></pre> <p>To build binaries:</p> <pre><code>tuist build\n</code></pre> <p>To run tests:</p> <pre><code>tuist test\n</code></pre>"},{"location":"ios/#design","title":"Design","text":""},{"location":"ios/#capabilities","title":"Capabilities","text":"<ul> <li>Create + name new gestures</li> <li>Record movement samples to train gesture recognition</li> <li>Connect gestures -&gt; actions<ul> <li>HomeKit API</li> <li>Shortcuts API</li> <li>Mouse input </li> </ul> </li> <li>Real-time classification of raw_data -&gt; gestures -&gt; actions</li> </ul>"},{"location":"ios/#resources","title":"Resources","text":""}]}